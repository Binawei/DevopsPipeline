name: Setup and Deploy Project

on:
  workflow_call:
    inputs:
      project_name:
        required: true
        type: string
      app_type:
        required: true
        type: string
      aws_region:
        required: false
        type: string
        default: "us-east-1"
      enable_database:
        required: false
        type: boolean
        default: false
      database_type:
        required: false
        type: string
        default: "postgres"
      database_instance_class:
        required: false
        type: string
        default: "db.t3.micro"
    secrets:
      AWS_ACCESS_KEY_ID:
        required: true
      AWS_SECRET_ACCESS_KEY:
        required: true
      EC2_SSH_KEY:
        required: false

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    environment: production-approval
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up JDK 17
      if: inputs.app_type == 'java-spring-boot'
      uses: actions/setup-java@v4
      with:
        java-version: '17'
        distribution: 'temurin'
    
    - name: Set up Node.js
      if: inputs.app_type == 'react-frontend' || inputs.app_type == 'node-backend'
      uses: actions/setup-node@v4
      with:
        node-version: '18'
    
    - name: Run tests (Java)
      if: inputs.app_type == 'java-spring-boot'
      run: ./mvnw clean test
    
    - name: Build application (Java)
      if: inputs.app_type == 'java-spring-boot'
      run: ./mvnw clean package -DskipTests
    
    - name: Install dependencies (Node)
      if: inputs.app_type == 'react-frontend' || inputs.app_type == 'node-backend'
      run: npm ci
    
    - name: Run tests (Node)
      if: inputs.app_type == 'react-frontend' || inputs.app_type == 'node-backend'
      run: npm test -- --coverage --watchAll=false
    
    - name: Build application (React)
      if: inputs.app_type == 'react-frontend'
      run: npm run build
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ inputs.aws_region }}
    
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2
    
    - name: Build and push Docker image
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        # Create ECR repository if it doesn't exist
        aws ecr describe-repositories --repository-names ${{ inputs.project_name }} || aws ecr create-repository --repository-name ${{ inputs.project_name }}
        
        # Build and push image
        docker build -t $ECR_REGISTRY/${{ inputs.project_name }}:$IMAGE_TAG .
        docker tag $ECR_REGISTRY/${{ inputs.project_name }}:$IMAGE_TAG $ECR_REGISTRY/${{ inputs.project_name }}:latest
        docker push $ECR_REGISTRY/${{ inputs.project_name }}:$IMAGE_TAG
        docker push $ECR_REGISTRY/${{ inputs.project_name }}:latest
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.0
    
    - name: Deploy infrastructure with Terraform
      env:
        TF_VAR_project_name: ${{ inputs.project_name }}
        TF_VAR_app_type: ${{ inputs.app_type }}
        TF_VAR_aws_region: ${{ inputs.aws_region }}
        TF_VAR_enable_database: ${{ inputs.enable_database }}
        TF_VAR_database_type: ${{ inputs.database_type }}
        TF_VAR_database_instance_class: ${{ inputs.database_instance_class }}
        TF_VAR_skip_asg_creation: ${{ env.SKIP_TERRAFORM_ASG }}
      run: |
        cd devops/terraform
        terraform init
        
        if [ "${{ env.SKIP_TERRAFORM_ASG }}" = "true" ]; then
          echo "Skipping Terraform ASG management - using existing instances"
          # Only apply non-ASG resources
          terraform plan -target=aws_security_group.app -target=aws_security_group.alb -target=aws_iam_role.ec2_role -target=aws_iam_role_policy.parameter_store_policy -target=aws_iam_instance_profile.ec2_profile
          terraform apply -auto-approve -target=aws_security_group.app -target=aws_security_group.alb -target=aws_iam_role.ec2_role -target=aws_iam_role_policy.parameter_store_policy -target=aws_iam_instance_profile.ec2_profile
        else
          echo "Running full Terraform deployment"
          terraform plan
          terraform apply -auto-approve
        fi
        
        # Get outputs
        echo "LOAD_BALANCER_DNS=$(terraform output -raw load_balancer_dns)" >> $GITHUB_ENV
        echo "ECR_REPOSITORY_URL=$(terraform output -raw ecr_repository_url)" >> $GITHUB_ENV
    
    - name: Check if instances already exist
      run: |
        # Check if there are already running instances
        EXISTING_INSTANCES=$(aws autoscaling describe-auto-scaling-groups \
          --auto-scaling-group-names "${{ inputs.project_name }}-asg" \
          --query 'AutoScalingGroups[0].Instances[?LifecycleState==`InService`].InstanceId' \
          --output text 2>/dev/null || echo "")
        
        echo "Existing instances: $EXISTING_INSTANCES"
        
        if [ -n "$EXISTING_INSTANCES" ] && [ "$EXISTING_INSTANCES" != "None" ]; then
          echo "Instances already exist, skipping Terraform ASG management"
          echo "SKIP_TERRAFORM_ASG=true" >> $GITHUB_ENV
          echo "SKIP_ASG_MANAGEMENT=true" >> $GITHUB_ENV
        else
          echo "No existing instances, will run full Terraform"
          echo "SKIP_TERRAFORM_ASG=false" >> $GITHUB_ENV
          echo "SKIP_ASG_MANAGEMENT=false" >> $GITHUB_ENV
        fi
    
    - name: Ensure Auto Scaling Group has instances
      if: env.SKIP_ASG_MANAGEMENT == 'false'
      run: |
        # Check current Auto Scaling Group status
        echo "Checking Auto Scaling Group status..."
        ASG_STATUS=$(aws autoscaling describe-auto-scaling-groups \
          --auto-scaling-group-names "${{ inputs.project_name }}-asg" \
          --query 'AutoScalingGroups[0].[MinSize,MaxSize,DesiredCapacity]' \
          --output text)
        
        echo "ASG Status (Min/Max/Desired): $ASG_STATUS"
        
        # Get current min size and set desired capacity accordingly
        MIN_SIZE=$(echo "$ASG_STATUS" | cut -f1)
        echo "Setting desired capacity to minimum size: $MIN_SIZE"
        
        aws autoscaling update-auto-scaling-group \
          --auto-scaling-group-name "${{ inputs.project_name }}-asg" \
          --desired-capacity $MIN_SIZE
        
        echo "Waiting for instances to launch..."
        sleep 60
    
    - name: Get running EC2 instances
      run: |
        # Get running instances from ASG
        for i in {1..5}; do
          echo "Attempt $i: Getting running instances from ASG..."
          
          INSTANCE_IDS=$(aws autoscaling describe-auto-scaling-groups \
            --auto-scaling-group-names "${{ inputs.project_name }}-asg" \
            --query 'AutoScalingGroups[0].Instances[?LifecycleState==`InService`].InstanceId' \
            --output text 2>/dev/null || echo "")
          
          echo "Instance IDs from ASG: $INSTANCE_IDS"
          
          if [ -n "$INSTANCE_IDS" ] && [ "$INSTANCE_IDS" != "None" ]; then
            # Verify instances are actually running
            RUNNING_INSTANCES=$(aws ec2 describe-instances \
              --instance-ids $INSTANCE_IDS \
              --query 'Reservations[].Instances[?State.Name==`running`].InstanceId' \
              --output text)
            
            echo "Running instances: $RUNNING_INSTANCES"
            
            if [ -n "$RUNNING_INSTANCES" ] && [ "$RUNNING_INSTANCES" != "None" ]; then
              echo "$RUNNING_INSTANCES" > /tmp/instance_ids.txt
              break
            fi
          fi
          
          echo "No running instances found, waiting 30 seconds..."
          sleep 30
        done
        
        if [ ! -f /tmp/instance_ids.txt ]; then
          echo "No running instances found after retries"
          exit 1
        fi
        
        echo "Found running instances: $(cat /tmp/instance_ids.txt)"
    
    - name: Deploy to EC2 via Systems Manager
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        # Read instance IDs
        INSTANCE_IDS=$(cat /tmp/instance_ids.txt)
        echo "Deploying to instances: $INSTANCE_IDS"
        
        # Wait for instances to be ready for SSM
        echo "Waiting for instances to be ready for Systems Manager..."
        for instance_id in $INSTANCE_IDS; do
          echo "Checking SSM status for instance: $instance_id"
          for i in {1..10}; do
            SSM_STATUS=$(aws ssm describe-instance-information \
              --filters "Key=InstanceIds,Values=$instance_id" \
              --query 'InstanceInformationList[0].PingStatus' \
              --output text 2>/dev/null || echo "NotFound")
            
            echo "Attempt $i: SSM Status for $instance_id: $SSM_STATUS"
            
            if [ "$SSM_STATUS" = "Online" ]; then
              echo "Instance $instance_id is ready for SSM"
              break
            fi
            
            if [ $i -eq 10 ]; then
              echo "Instance $instance_id not ready for SSM after 10 attempts. Trying manual restart..."
              # Try to restart SSM agent
              aws ssm send-command \
                --instance-ids "$instance_id" \
                --document-name "AWS-RunShellScript" \
                --parameters 'commands=["sudo systemctl restart amazon-ssm-agent"]' \
                --comment "Restart SSM agent" || echo "Failed to restart SSM agent"
              sleep 60
            fi
            
            sleep 30
          done
        done
        
        # Deploy to each instance via SSM
        for instance_id in $INSTANCE_IDS; do
          echo "Deploying to instance: $instance_id"
          COMMAND_ID=$(aws ssm send-command \
            --instance-ids "$instance_id" \
            --document-name "AWS-RunShellScript" \
            --parameters 'commands=[
              "aws ecr get-login-password --region ${{ inputs.aws_region }} | docker login --username AWS --password-stdin $ECR_REGISTRY",
              "docker stop ${{ inputs.project_name }} || true",
              "docker rm ${{ inputs.project_name }} || true",
              "docker pull $ECR_REGISTRY/${{ inputs.project_name }}:$IMAGE_TAG",
              "docker run -d --name ${{ inputs.project_name }} -p 8080:8080 -e SPRING_PROFILES_ACTIVE=production -e PROJECT_NAME=${{ inputs.project_name }} -e AWS_REGION=${{ inputs.aws_region }} --restart unless-stopped $ECR_REGISTRY/${{ inputs.project_name }}:$IMAGE_TAG"
            ]' \
            --comment "Deploy ${{ inputs.project_name }} via GitHub Actions" \
            --query 'Command.CommandId' --output text)
          
          echo "Command sent with ID: $COMMAND_ID"
        done
        
        echo "Deployment commands sent to all instances"
    
    - name: Output deployment info
      run: |
        echo "üéâ Deployment completed successfully!"
        echo "üåê Application URL: http://${{ env.LOAD_BALANCER_DNS }}"
        echo "üì¶ Docker Image: ${{ env.ECR_REPOSITORY_URL }}:${{ github.sha }}"