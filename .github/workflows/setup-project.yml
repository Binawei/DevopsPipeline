name: Setup and Deploy Project

on:
  workflow_call:
    inputs:
      project_name:
        required: true
        type: string
      app_type:
        required: true
        type: string
      aws_region:
        required: false
        type: string
        default: "us-east-1"
      enable_database:
        required: false
        type: boolean
        default: false
      database_type:
        required: false
        type: string
        default: "postgres"
      database_instance_class:
        required: false
        type: string
        default: "db.t3.micro"
    secrets:
      AWS_ACCESS_KEY_ID:
        required: true
      AWS_SECRET_ACCESS_KEY:
        required: true
      EC2_SSH_KEY:
        required: false

jobs:
  build-and-deploy:
    runs-on: ubuntu-latest
    environment: production-approval
    
    steps:
    - name: Checkout code
      uses: actions/checkout@v4
    
    - name: Set up JDK 17
      if: inputs.app_type == 'java-spring-boot'
      uses: actions/setup-java@v4
      with:
        java-version: '17'
        distribution: 'temurin'
    
    - name: Set up Node.js
      if: inputs.app_type == 'react-frontend' || inputs.app_type == 'node-backend'
      uses: actions/setup-node@v4
      with:
        node-version: '18'
    
    - name: Run tests (Java)
      if: inputs.app_type == 'java-spring-boot'
      run: ./mvnw clean test
    
    - name: Build application (Java)
      if: inputs.app_type == 'java-spring-boot'
      run: ./mvnw clean package -DskipTests
    
    - name: Install dependencies (Node)
      if: inputs.app_type == 'react-frontend' || inputs.app_type == 'node-backend'
      run: npm ci
    
    - name: Run tests (Node)
      if: inputs.app_type == 'react-frontend' || inputs.app_type == 'node-backend'
      run: npm test -- --coverage --watchAll=false
    
    - name: Build application (React)
      if: inputs.app_type == 'react-frontend'
      run: npm run build
    
    - name: Configure AWS credentials
      uses: aws-actions/configure-aws-credentials@v4
      with:
        aws-access-key-id: ${{ secrets.AWS_ACCESS_KEY_ID }}
        aws-secret-access-key: ${{ secrets.AWS_SECRET_ACCESS_KEY }}
        aws-region: ${{ inputs.aws_region }}
    
    - name: Login to Amazon ECR
      id: login-ecr
      uses: aws-actions/amazon-ecr-login@v2
    
    - name: Build and push Docker image
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        # Create ECR repository if it doesn't exist
        aws ecr describe-repositories --repository-names ${{ inputs.project_name }} || aws ecr create-repository --repository-name ${{ inputs.project_name }}
        
        # Build and push image
        docker build -t $ECR_REGISTRY/${{ inputs.project_name }}:$IMAGE_TAG .
        docker tag $ECR_REGISTRY/${{ inputs.project_name }}:$IMAGE_TAG $ECR_REGISTRY/${{ inputs.project_name }}:latest
        docker push $ECR_REGISTRY/${{ inputs.project_name }}:$IMAGE_TAG
        docker push $ECR_REGISTRY/${{ inputs.project_name }}:latest
    
    - name: Setup Terraform
      uses: hashicorp/setup-terraform@v3
      with:
        terraform_version: 1.5.0
    
    - name: Deploy infrastructure with Terraform
      env:
        TF_VAR_project_name: ${{ inputs.project_name }}
        TF_VAR_app_type: ${{ inputs.app_type }}
        TF_VAR_aws_region: ${{ inputs.aws_region }}
        TF_VAR_enable_database: ${{ inputs.enable_database }}
        TF_VAR_database_type: ${{ inputs.database_type }}
        TF_VAR_database_instance_class: ${{ inputs.database_instance_class }}
      run: |
        cd devops/terraform
        terraform init
        terraform plan
        terraform apply -auto-approve
        
        # Get outputs
        echo "LOAD_BALANCER_DNS=$(terraform output -raw load_balancer_dns)" >> $GITHUB_ENV
        echo "ECR_REPOSITORY_URL=$(terraform output -raw ecr_repository_url)" >> $GITHUB_ENV
    
    - name: Check if instances already exist
      run: |
        # Check if there are already running instances
        EXISTING_INSTANCES=$(aws autoscaling describe-auto-scaling-groups \
          --auto-scaling-group-names "${{ inputs.project_name }}-asg" \
          --query 'AutoScalingGroups[0].Instances[?LifecycleState==`InService`].InstanceId' \
          --output text)
        
        echo "Existing instances: $EXISTING_INSTANCES"
        
        if [ -n "$EXISTING_INSTANCES" ]; then
          echo "Instances already exist, skipping ASG management"
          echo "SKIP_ASG_MANAGEMENT=true" >> $GITHUB_ENV
        else
          echo "No existing instances, will manage ASG"
          echo "SKIP_ASG_MANAGEMENT=false" >> $GITHUB_ENV
        fi
    
    - name: Ensure Auto Scaling Group has instances
      if: env.SKIP_ASG_MANAGEMENT == 'false'
      run: |
        # Check current Auto Scaling Group status
        echo "Checking Auto Scaling Group status..."
        ASG_STATUS=$(aws autoscaling describe-auto-scaling-groups \
          --auto-scaling-group-names "${{ inputs.project_name }}-asg" \
          --query 'AutoScalingGroups[0].[MinSize,MaxSize,DesiredCapacity]' \
          --output text)
        
        echo "ASG Status (Min/Max/Desired): $ASG_STATUS"
        
        # Get current min size and set desired capacity accordingly
        MIN_SIZE=$(echo "$ASG_STATUS" | cut -f1)
        echo "Setting desired capacity to minimum size: $MIN_SIZE"
        
        aws autoscaling update-auto-scaling-group \
          --auto-scaling-group-name "${{ inputs.project_name }}-asg" \
          --desired-capacity $MIN_SIZE
        
        echo "Waiting for instances to launch..."
        sleep 60
    
    - name: Get EC2 instance IPs and create inventory
      run: |
        # Get Auto Scaling Group instances (retry logic)
        for i in {1..5}; do
          echo "Attempt $i: Getting Auto Scaling Group instances..."
          
          # First try InService instances
          INSTANCE_IDS=$(aws autoscaling describe-auto-scaling-groups \
            --auto-scaling-group-names "${{ inputs.project_name }}-asg" \
            --query 'AutoScalingGroups[0].Instances[?LifecycleState==`InService`].InstanceId' \
            --output text)
          
          # If no InService instances, try all instances
          if [ -z "$INSTANCE_IDS" ]; then
            echo "No InService instances, checking all instances..."
            INSTANCE_IDS=$(aws autoscaling describe-auto-scaling-groups \
              --auto-scaling-group-names "${{ inputs.project_name }}-asg" \
              --query 'AutoScalingGroups[0].Instances[].InstanceId' \
              --output text)
          fi
          
          echo "Instance IDs: $INSTANCE_IDS"
          
          # If we have instances, check if they're running
          if [ -n "$INSTANCE_IDS" ]; then
            RUNNING_IPS=$(aws ec2 describe-instances \
              --instance-ids $INSTANCE_IDS \
              --query 'Reservations[].Instances[?State.Name==`running`].PublicIpAddress' \
              --output text)
            
            echo "Running instance IPs: $RUNNING_IPS"
            
            if [ -n "$RUNNING_IPS" ]; then
              # Store IPs for later use
              echo "$RUNNING_IPS" > /tmp/instance_ips.txt
              break
            fi
          fi
          
          echo "No running instances found, waiting 30 seconds..."
          sleep 30
        done
        
        # Check if we found any running instances
        if [ ! -f /tmp/instance_ips.txt ]; then
          echo "No running instances found after retries"
          exit 1
        fi
        
        # Read the IPs we found
        IPS=$(cat /tmp/instance_ips.txt)
        echo "Using IPs: $IPS"
        
        # Create dynamic inventory
        echo "[production]" > devops/ansible/dynamic-inventory
        i=1
        for ip in $IPS; do
          if [ "$ip" != "None" ] && [ -n "$ip" ]; then
            echo "$ip ansible_user=ec2-user" >> devops/ansible/dynamic-inventory
            i=$((i+1))
          fi
        done
        echo "" >> devops/ansible/dynamic-inventory
        echo "[production:vars]" >> devops/ansible/dynamic-inventory
        echo "environment=production" >> devops/ansible/dynamic-inventory
        
        echo "Generated inventory:"
        cat devops/ansible/dynamic-inventory
    
    - name: Deploy to EC2 via Systems Manager
      env:
        ECR_REGISTRY: ${{ steps.login-ecr.outputs.registry }}
        IMAGE_TAG: ${{ github.sha }}
      run: |
        # Read instance IPs
        IPS=$(cat /tmp/instance_ips.txt)
        
        # Get instance IDs from IPs
        INSTANCE_IDS=$(aws ec2 describe-instances \
          --filters "Name=ip-address,Values=$(echo $IPS | tr ' ' ',')" "Name=instance-state-name,Values=running" \
          --query 'Reservations[].Instances[].InstanceId' \
          --output text)
        
        echo "Deploying to instances: $INSTANCE_IDS"
        
        # Wait for instances to be ready for SSM
        echo "Waiting for instances to be ready for Systems Manager..."
        for instance_id in $INSTANCE_IDS; do
          echo "Checking SSM status for instance: $instance_id"
          for i in {1..10}; do
            SSM_STATUS=$(aws ssm describe-instance-information \
              --filters "Key=InstanceIds,Values=$instance_id" \
              --query 'InstanceInformationList[0].PingStatus' \
              --output text 2>/dev/null || echo "NotFound")
            
            echo "Attempt $i: SSM Status for $instance_id: $SSM_STATUS"
            
            if [ "$SSM_STATUS" = "Online" ]; then
              echo "Instance $instance_id is ready for SSM"
              break
            fi
            
            if [ $i -eq 10 ]; then
              echo "Instance $instance_id not ready for SSM after 10 attempts"
              exit 1
            fi
            
            sleep 30
          done
        done
        
        # Deploy to each instance via SSM
        for instance_id in $INSTANCE_IDS; do
          echo "Deploying to instance: $instance_id"
          COMMAND_ID=$(aws ssm send-command \
            --instance-ids "$instance_id" \
            --document-name "AWS-RunShellScript" \
            --parameters 'commands=[
              "aws ecr get-login-password --region ${{ inputs.aws_region }} | docker login --username AWS --password-stdin $ECR_REGISTRY",
              "docker stop ${{ inputs.project_name }} || true",
              "docker rm ${{ inputs.project_name }} || true",
              "docker pull $ECR_REGISTRY/${{ inputs.project_name }}:$IMAGE_TAG",
              "docker run -d --name ${{ inputs.project_name }} -p 8080:8080 -e SPRING_PROFILES_ACTIVE=production -e PROJECT_NAME=${{ inputs.project_name }} -e AWS_REGION=${{ inputs.aws_region }} --restart unless-stopped $ECR_REGISTRY/${{ inputs.project_name }}:$IMAGE_TAG"
            ]' \
            --comment "Deploy ${{ inputs.project_name }} via GitHub Actions" \
            --query 'Command.CommandId' --output text)
          
          echo "Command sent with ID: $COMMAND_ID"
        done
        
        echo "Deployment commands sent to all instances"
    
    - name: Output deployment info
      run: |
        echo "üéâ Deployment completed successfully!"
        echo "üåê Application URL: http://${{ env.LOAD_BALANCER_DNS }}"
        echo "üì¶ Docker Image: ${{ env.ECR_REPOSITORY_URL }}:${{ github.sha }}"